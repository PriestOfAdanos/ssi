{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # csv files\n",
    "import random\n",
    "from math import sqrt \n",
    "\n",
    "iris=pd.read_csv('seeds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    " def gauss(x,mean,std):\n",
    "    # x - jedna z wartości sample [a,b,c,d]\n",
    "    if x<(mean-(sqrt(6)*std)) or x>(mean+(sqrt(6)*std)):\n",
    "        return 0\n",
    "    if (mean-(sqrt(6)*std))<=x<=mean:\n",
    "        return ((x-mean)/(6*std**2))+(1/(sqrt(6)*std))\n",
    "    if mean<x<=(mean+(sqrt(6)*std)):\n",
    "        return (-(x-mean)/(6*std**2))+(1/(sqrt(6)*std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayess_clasifier(training_set, sample_to_classify, iris_species_list):\n",
    "    data = ProcessingData(training_set)\n",
    "    stds = data.std()\n",
    "    means = data.mean()\n",
    "    probabilities = {}\n",
    "    for name in iris_species_list:\n",
    "        probabilities[name]=1\n",
    "        for key in sample_to_classify.keys():\n",
    "            probabilities[name]*=(gauss(sample_to_classify[key],means[name][key],stds[name][key]))\n",
    "    guess = max(probabilities, key= lambda x: probabilities[x])\n",
    "    return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessingData:\n",
    "    def __init__(self, flowers_table):\n",
    "        self.flowers_table = flowers_table\n",
    "\n",
    "    def stiffle(self):\n",
    "        x = self.flowers_table.copy()\n",
    "        for i in range(len(x)-1,0,-1):\n",
    "            tmp = random.randint(0,i)\n",
    "            x.iloc[i], x.iloc[tmp] = x.iloc[tmp], x.iloc[i]\n",
    "        return ProcessingData(x)\n",
    "    \n",
    "    def normalize(self):\n",
    "        flower_data = self.flowers_table.loc[:, self.flowers_table.columns!='Type']\n",
    "        iris_species = self.flowers_table.loc[:, self.flowers_table.columns=='Type']\n",
    "        normalized_df=(flower_data-flower_data.min())/(flower_data.max()-flower_data.min())\n",
    "        normalized_df['Type']=iris_species\n",
    "        return ProcessingData(normalized_df)    \n",
    "    \n",
    "    def mean(self):    \n",
    "        mean = pd.DataFrame()\n",
    "        for i, name in enumerate(self.flowers_table.Type.unique()):\n",
    "            mean[name] = self.flowers_table[self.flowers_table['Type'] == name].mean(axis=0)  \n",
    "        return mean\n",
    "    \n",
    "    def MAX(self):    \n",
    "        MAX = pd.DataFrame()\n",
    "        for i, name in enumerate(self.flowers_table.Type.unique()):\n",
    "            MAX[name] = self.flowers_table[self.flowers_table['Type'] == name].max(0)\n",
    "        return MAX\n",
    "    \n",
    "    def MIN(self):    \n",
    "        MIN = pd.DataFrame()\n",
    "        for i, name in enumerate(self.flowers_table.Type.unique()):\n",
    "            MIN[name] = self.flowers_table[self.flowers_table['Type'] == name].min(0)\n",
    "        return MIN\n",
    "    \n",
    "    def std(self): # można zastąpić p.std()\n",
    "        self.mean()\n",
    "        std = self.mean().copy()\n",
    "        for Type in self.flowers_table['Type'].unique():\n",
    "            for prop in ['Area','Perimeter',\n",
    "                                 'Compactness',\n",
    "                                 'Kernel.Length',\n",
    "                                 'Kernel.Width',\n",
    "                                 'Asymmetry.Coeff',\n",
    "                                 'Kernel.Groove']:\n",
    "                \n",
    "                \n",
    "                std[Type][prop]=self.flowers_table[self.flowers_table['Type']==Type][prop].sub(self.mean()[Type][prop]).pow(2).mean()\n",
    "        return std\n",
    "    \n",
    "    def split(self,a):\n",
    "        x = self.flowers_table\n",
    "        n = len(x)\n",
    "        tabA=x[0:int(a*n)]\n",
    "        tabB=x[int(a*n):n]\n",
    "        return tabA, tabB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iris = ProcessingData(iris)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisTrain2, irisVal2 = Iris.split(0.7)\n",
    "\n",
    "irisTrain, irisVal = Iris.stiffle().normalize().split(0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [1,2,3]\n",
    "accuracy=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  38.333333333333336 %\n"
     ]
    }
   ],
   "source": [
    "for i in irisVal.iloc:\n",
    "    sample = pd.DataFrame()\n",
    "    #print(i['sepal.length'].item)\n",
    "    \n",
    "    \n",
    "    \n",
    "    sample = {\n",
    "        'Area':i['Area'],\n",
    "     'Perimeter':i['Perimeter'],\n",
    "     'Compactness':i['Compactness'],\n",
    "     'Kernel.Length':i['Kernel.Length'],\n",
    "     'Kernel.Width':i['Kernel.Width'],\n",
    "     'Asymmetry.Coeff':i['Asymmetry.Coeff'],\n",
    "     'Kernel.Groove':i['Kernel.Groove']\n",
    "    }\n",
    "    \n",
    "    answear = naive_bayess_clasifier(irisTrain,sample,types)\n",
    "    if(answear == i.Type):\n",
    "        accuracy+=1\n",
    "print('accuracy = ',(accuracy/len(irisVal)*100),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in irisVal2.iloc:\n",
    "    sample = pd.DataFrame()\n",
    "    #print(i['sepal.length'].item)\n",
    "    \n",
    "    \n",
    "    \n",
    "    sample = {\n",
    "        'Area':i['Area'],\n",
    "     'Perimeter':i['Perimeter'],\n",
    "     'Compactness':i['Compactness'],\n",
    "     'Kernel.Length':i['Kernel.Length'],\n",
    "     'Kernel.Width':i['Kernel.Width'],\n",
    "     'Asymmetry.Coeff':i['Asymmetry.Coeff'],\n",
    "     'Kernel.Groove':i['Kernel.Groove']\n",
    "    }\n",
    "    \n",
    "    answear = naive_bayess_clasifier(irisTrain2,sample,types)\n",
    "    if(answear == i.Type):\n",
    "        accuracy+=1\n",
    "print('accuracy = ',(accuracy/len(irisVal)*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    @staticmethod\n",
    "    def minkowskiMetric(v1,v2,m):\n",
    "\n",
    "        dim = len(v1)-1\n",
    "        distance=0\n",
    "        for i in range(dim):\n",
    "            distance+=(abs(v1[i]-v2[i])) #**m)\n",
    "        #distance = distance #**(1/m)\n",
    "        return distance\n",
    "\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def KLASTERYZACJA(testSample, x, k, classes):\n",
    "        # odległość\n",
    "        distances=[]\n",
    "        for i in x.index:\n",
    "            distances.append(KNN.minkowskiMetric(testSample,x.iloc[i],2))\n",
    "        \n",
    "        # sortowanie - po distances, ale zamieniamy w treningowym\n",
    "        \n",
    "        xs = x.copy()\n",
    "        \n",
    "        n=len(distances)\n",
    "        \n",
    "        i=0\n",
    "        while(i<n):\n",
    "            temp = distances[i]\n",
    "            tempx=xs.iloc[i]\n",
    "            ind = distances.index(min(distances[i:n]))\n",
    "            distances[ind], distances[i] = distances[i], distances[ind]\n",
    "            xs.iloc[i], xs.iloc[ind] = xs.iloc[ind], xs.iloc[i]\n",
    "            i+=1\n",
    "\n",
    "        #while n>1:\n",
    "        #    for i in range(0,n-1,1):\n",
    "        #        if distances[i+1]>distances[i]:\n",
    "        #            distances[i+1], distances[i] = distances[i], distances[i+1]\n",
    "        #            xs.iloc[i], xs.iloc[i+1] = xs.iloc[i+1], xs.iloc[i]\n",
    "        #    n-=1\n",
    "        \n",
    "        # głosowanie\n",
    "        for i in range(0,k,1):\n",
    "            classes[xs.iloc[i].Type]+=1\n",
    "            \n",
    "        # zwrot wyniku\n",
    "        return max(classes,key=classes.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [4]:\n",
    "    corrected=0\n",
    "    for i in range(len(irisVal)):\n",
    "        classes = {1:0, 2:0, 3:0}\n",
    "        final = KNN.KLASTERYZACJA(irisVal.iloc[i],irisTrain,k,classes)\n",
    "        if (final == irisVal.iloc[i].Type):\n",
    "            corrected+=1\n",
    "\n",
    "    accuracy=corrected/len(irisVal)*100\n",
    "    print('accuracy for k=',k,'is', accuracy)\n",
    "    \n",
    "for k in [4]:\n",
    "    corrected=0\n",
    "    for i in range(len(irisVal2)):\n",
    "        classes = {1:0, 2:0, 3:0}\n",
    "        final = KNN.KLASTERYZACJA(irisVal2.iloc[i],irisTrain2,k,classes)\n",
    "        if (final == irisVal2.iloc[i].Type):\n",
    "            corrected+=1\n",
    "\n",
    "    accuracy=corrected/len(irisVal2)*100\n",
    "    print('accuracy for k=',k,'is', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_set(x, Irs):\n",
    "    scores={1:0,2:0,3:0}\n",
    "    mx = ProcessingData(Irs).MAX()\n",
    "    mn = ProcessingData(Irs).MIN()\n",
    "\n",
    "    for i in [1,2,3]:\n",
    "        for param in irisTrain.columns.tolist()[:-1]:\n",
    "            scores[i]+=mn[i][param]<x[param]<mx[i][param]\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_main(Irs):\n",
    "    acc = 0\n",
    "    for index, row in Irs.iterrows():\n",
    "        scores = soft_set(row,Irs)\n",
    "        if max(scores, key=scores.get)==row[\"Type\"]:\n",
    "            acc+=1\n",
    "    return acc/len(Irs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"accuracy of soft set classifier on normalized data is {soft_main(irisTrain)*100}%\")\n",
    "print(f\"accuracy of soft set classifier data \\\"as is\\\" is {soft_main(irisTrain2)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
